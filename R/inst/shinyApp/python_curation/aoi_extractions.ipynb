{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# curating  data for an area of interest\n",
    "\n",
    "- easy to do a for a single AOI, just update and re-run script for different AOI.\n",
    "Inefficient as we start wanting to look at more.\n",
    "- Update code relative to `aoi_calculations.ipynb` to try to keep things grouped\n",
    "by region\n",
    "\n",
    "\n",
    "# Import general packages\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import stitches as stitches\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting options\n",
    "sns.set(font_scale=1.3)\n",
    "sns.set_style(\"white\")\n",
    "# For help with plotting\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# import packages for spatial masking"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "# Spatial subsetting of netcdf files:\n",
    "import regionmask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Set up time slices and area of interest (AOI) to focus on\n",
    "\n",
    "- require ensemble average PR values over the ref period and comparison period\n",
    "for an area of interest\n",
    "- Do spatial aggregation for each ensemble member, take the time average in the\n",
    "time window, calculate average across ensemble members"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Time slices\n",
    "ref_start = 1980\n",
    "ref_end =  2014\n",
    "\n",
    "comp_start = 2015\n",
    "comp_end =  2099\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# AOI\n",
    "# working off https://www.earthdatascience.org/courses/use-data-open-source-python/hierarchical-data-formats-hdf/subset-netcdf4-climate-data-spatially-aoi/\n",
    "\n",
    "# # physical land polygon files:\n",
    "# url =  (    \"https://naturalearth.s3.amazonaws.com/\"\n",
    "# \"10m_physical/ne_10m_land.zip\")\n",
    "\n",
    "# # country URL\n",
    "# url =  (    \"https://naturalearth.s3.amazonaws.com/\"\n",
    "#             \"10m_cultural/ne_10m_admin_0_countries.zip\")\n",
    "\n",
    "# # state/province URL\n",
    "# url =  (    \"https://naturalearth.s3.amazonaws.com/\"\n",
    "#             \"10m_cultural/ne_10m_admin_1_states_provinces.zip\")\n",
    "\n",
    "# IPCC ar6 reference regions - including ocean regions\n",
    "# actually have to download locally from\n",
    "# https://github.com/IPCC-WG1/Atlas/blob/main/reference-regions/IPCC-WGI-reference-regions-v4_shapefile.zip\n",
    "url =  (   'IPCC-WGI-reference-regions-v4_shapefile.zip')\n",
    "\n",
    "land_main_gdf = gpd.read_file(url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IPCC_names  = land_main_gdf['Acronym'].unique()\n",
    "\n",
    "land_main_gdf.plot()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# specify ESMs, variables, experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The CMIP6 ESM we want to emulate and the variables we want to\n",
    "# emulate\n",
    "# NOTE IPSL and GFDL submitted results under grids labeled not `gn` so they\n",
    "# are not included in the stitches patches data. To pull their ESMs, we have to\n",
    "# source the pangeo table directly from pangeo and reshape it instead of using\n",
    "# the stitches package data.\n",
    "\n",
    "\n",
    "esm = ['CAMS-CSM1-0', 'MIROC6', 'GFDL-ESM4', 'FGOALS-g3',\n",
    "'MPI-ESM1-2-HR', 'MPI-ESM1-2-LR', 'MRI-ESM2-0',\n",
    "'ACCESS-ESM1-5', 'IPSL-CM6A-LR', 'CESM2-WACCM',\n",
    "'UKESM1-0-LL',\n",
    "'CanESM5']\n",
    "\n",
    "vars1 = ['tas']\n",
    "\n",
    "exps = ['historical',\n",
    "        'ssp126', 'ssp245', 'ssp370',  'ssp585',\n",
    "        'ssp460', 'ssp119',   'ssp434', 'ssp534-over']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pull pangeo dataframe with netcdf addresses for above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pangeo table of ESMs for reference\n",
    "pangeo_data = stitches.fx_pangeo.fetch_pangeo_table()\n",
    "\n",
    "pangeo_data = pangeo_data[(pangeo_data['source_id'].isin(esm)) &\n",
    "                           (pangeo_data['variable_id'].isin(vars1)) &(pangeo_data['table_id'] == 'Amon')&\n",
    "                           ((pangeo_data['experiment_id'].isin(exps)))].copy()\n",
    "\n",
    "# reshape to look like package data but with the ESMs we want to include\n",
    "pangeo_data = pangeo_data[[\"source_id\", \"experiment_id\", \"member_id\", \"variable_id\", \"grid_label\",\n",
    "                                                        \"zstore\", \"table_id\"]].copy()\n",
    "pangeo_data = pangeo_data.rename(columns={\"source_id\": \"model\", \"experiment_id\": \"experiment\",\n",
    "                                                \"member_id\": \"ensemble\", \"variable_id\": \"variable\",\n",
    "                                                \"zstore\": \"zstore\", \"table_id\": \"domain\"}).reset_index(drop = True).copy()\n",
    "\n",
    " # keep only p1 runs:\n",
    "# UK model only does f2 runs for some reason\n",
    "ukesm_data =  pangeo_data[pangeo_data['model'].str.contains('UKESM')].copy()\n",
    "ukesm_data = ukesm_data[ukesm_data['ensemble'].str.contains('i1p1f2')].copy()\n",
    "\n",
    "# everyone else does f1 runs\n",
    "pangeo_data = pangeo_data[pangeo_data['ensemble'].str.contains('i1p1f1')].copy()\n",
    "\n",
    "# combine UKESM with other models\n",
    "pangeo_data = pd.concat([pangeo_data, ukesm_data]).reset_index(drop=True).copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# loop over files and do calculations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aoi = land_main_gdf.reset_index(drop=True).copy()\n",
    "aoi = aoi[aoi['Type']!= 'Ocean'].copy()\n",
    "aoi = aoi[aoi['Continent'] != 'POLAR'].reset_index(drop=True).copy()\n",
    "\n",
    "aoi_labels = aoi[['Continent', 'Type', 'Name', 'Acronym']].copy()\n",
    "aoi_labels = aoi_labels.rename(columns={'Continent':'continent',\n",
    "                                        'Type':'type',\n",
    "                                        'Name':'name',\n",
    "                                        'Acronym':'acronym'}).copy()\n",
    "aoi_labels['region'] = aoi_labels.index.copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Updated\n",
    "\n",
    "varname = vars1[0]\n",
    "\n",
    "timeseries_holder = pd.DataFrame()\n",
    "\n",
    "for esmname in esm:\n",
    "  for exp in exps:\n",
    "\n",
    "    print(esmname)\n",
    "    print(exp)\n",
    "\n",
    "    filelist = pangeo_data[(pangeo_data['model'] ==esmname) & (pangeo_data['experiment'] == exp)].copy()\n",
    "\n",
    "    if filelist.empty:\n",
    "        print('no ensemble members for this exp')\n",
    "        # end if no files for experiment\n",
    "\n",
    "    if not filelist.empty:\n",
    "        for i in range(len(filelist)):\n",
    "            print(i)\n",
    "\n",
    "            # Load data:\n",
    "            x = stitches.fx_pangeo.fetch_nc(filelist.iloc[i].zstore)\n",
    "            x = x.sortby('time').copy()\n",
    "\n",
    "            # If it's the first ensemble member, set up the mask\n",
    "            if (i==0):\n",
    "                aoi_mask = regionmask.mask_3D_geopandas(aoi,\n",
    "                                                        x.lon,\n",
    "                                                        x.lat)\n",
    "                # end if i==0 set up aoi_mask\n",
    "\n",
    "            # mask the file\n",
    "            x = x.where(aoi_mask).copy()\n",
    "\n",
    "            # If the experiment is historical, further slice to reference years.\n",
    "            # Otherwise, slice to comparison years:\n",
    "            if (exp == 'historical'):\n",
    "                window_length = ref_end-ref_start+1\n",
    "                if(esmname == 'UKESM1-0-LL'):\n",
    "                    x = x.sel(time=slice(str(ref_start)+'-01-01',\n",
    "                                         '2014-12-30')).copy()\n",
    "                if(esmname != 'UKESM1-0-LL'):\n",
    "                    x = x.sel(time=slice(str(ref_start)+'-01-01',\n",
    "                                         str(ref_end)+'-12-31')).copy()\n",
    "\n",
    "            if (exp!='historical'):\n",
    "                window_length = comp_end-comp_start +1\n",
    "                if(esmname == 'UKESM1-0-LL'):\n",
    "                    x = x.sel(time=slice(str(comp_start)+'-01-01',\n",
    "                                         '2099-12-30')).copy()\n",
    "                if(esmname != 'UKESM1-0-LL'):\n",
    "                    x = x.sel(time=slice(str(comp_start)+'-01-01',\n",
    "                                         str(comp_end)+'-12-31')).copy()\n",
    "\n",
    "                # end if checks for time slicing\n",
    "\n",
    "            # Check if there are the correct number of time steps in this\n",
    "            # sliced data:\n",
    "            # Very rough QC for checking complete netcdfs and assumes\n",
    "            # comparison window and reference window same length.\n",
    "            if (len(x.time) >= 12*window_length):\n",
    "                annual_aoi = pd.DataFrame()\n",
    "                for name, group in x.groupby('region'):\n",
    "                    # aggregate to the region for each month, then calculate annual avg and reshape\n",
    "                    lat = group['lat']\n",
    "                    area = np.cos(np.deg2rad(lat))\n",
    "                    area.name = 'weights'\n",
    "                    group = group.weighted(area).mean((\"lon\", \"lat\")).coarsen(time=12).mean()\\\n",
    "                        [varname].to_dataframe().reset_index().drop('height', axis=1).copy()\n",
    "                    annual_aoi = pd.concat([annual_aoi, group]).reset_index(drop=True).copy()\n",
    "                    del(lat)\n",
    "                    del(area)\n",
    "                    # end for loop over regions\n",
    "\n",
    "                # add labeling\n",
    "                annual_aoi = annual_aoi.rename(columns={'tas':'ann_agg'}).copy()\n",
    "                annual_aoi['year'] = annual_aoi['time'].apply(lambda x: x.year).copy()\n",
    "                annual_aoi = annual_aoi.drop('time', axis=1).copy()\n",
    "                annual_aoi['esm'] = filelist.iloc[i].model\n",
    "                annual_aoi['experiment'] =  filelist.iloc[i].experiment\n",
    "                annual_aoi['ensemble'] = filelist.iloc[i].ensemble\n",
    "                annual_aoi['variable'] = filelist.iloc[i].variable\n",
    "                annual_aoi = annual_aoi.merge(aoi_labels, on = 'region', how = 'left').drop(['region'], axis=1).copy()\n",
    "                timeseries_holder = pd.concat([timeseries_holder, annual_aoi]).reset_index(drop=True).copy()\n",
    "                # end check if is complete data file and subsequent aggregations\n",
    "\n",
    "            # end for loop over file list\n",
    "\n",
    "    del(filelist)\n",
    "    del(annual_aoi)\n",
    "    del(window_length)\n",
    "    # end loop over experiments\n",
    "# end loop over esms\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timeseries_holder.to_csv(('IPCC_land_regions_'+ varname+ '_allesms_timeseries_' + str(ref_start) + '_' + str(comp_end) +'.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df = pd.read_csv('xarray_test.csv')\n",
    "#\n",
    "# compare = timeseries_holder.merge(df,\n",
    "#                                   on = ['year', 'esm', 'experiment', 'ensemble', 'variable',\n",
    "#                                         'continent',\t'type',\t'name',\t'acronym'],\n",
    "#                                   how = 'left').copy()\n",
    "#\n",
    "# np.max(np.abs(compare.ann_agg_x-compare.ann_agg_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-58c3bd78",
   "language": "python",
   "display_name": "PyCharm (python_curation)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}