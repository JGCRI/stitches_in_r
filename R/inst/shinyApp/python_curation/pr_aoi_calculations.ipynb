{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# curating pr data\n",
    "\n",
    "# Import general packages\n",
    "- if it is the first time running this notebook, will need to set up environment ->\n",
    "locally I'm just using my stitches interpreter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import stitches as stitches\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting options\n",
    "sns.set(font_scale=1.3)\n",
    "sns.set_style(\"white\")\n",
    "# For help with plotting\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# import packages for spatial masking"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "# Spatial subsetting of netcdf files:\n",
    "import regionmask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Set up time slices and area of interest (AOI) to focus on\n",
    "\n",
    "- require ensemble average PR values over the ref period and comparison period\n",
    "for an area of interest\n",
    "- Do spatial aggregation for each ensemble member, take the time average in the\n",
    "time window, calculate average across ensemble members"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Time slices\n",
    "ref_start = '1995-01-01'\n",
    "ref_end =  '2014-12-31'\n",
    "\n",
    "comp_start = '2080-01-01'\n",
    "comp_end =  '2099-12-31'\n",
    "\n",
    "window_length = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# AOI\n",
    "# working off https://www.earthdatascience.org/courses/use-data-open-source-python/hierarchical-data-formats-hdf/subset-netcdf4-climate-data-spatially-aoi/\n",
    "\n",
    "# # physical land polygon files:\n",
    "# url =  (    \"https://naturalearth.s3.amazonaws.com/\"\n",
    "# \"10m_physical/ne_10m_land.zip\")\n",
    "\n",
    "# # country URL\n",
    "# url =  (    \"https://naturalearth.s3.amazonaws.com/\"\n",
    "#             \"10m_cultural/ne_10m_admin_0_countries.zip\")\n",
    "\n",
    "# state/province URL\n",
    "url =  (    \"https://naturalearth.s3.amazonaws.com/\"\n",
    "            \"10m_cultural/ne_10m_admin_1_states_provinces.zip\")\n",
    "\n",
    "\n",
    "land_main_gdf = gpd.read_file(url)\n",
    "land_main_gdf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define conus as AOI\n",
    "aoi = land_main_gdf[(land_main_gdf['admin'] == 'United States of America')&\n",
    "                    (land_main_gdf['name'] != 'Hawaii') &\n",
    "                     (land_main_gdf['name'] != 'Alaska') ].reset_index(drop=True).copy()\n",
    "\n",
    "print(aoi.total_bounds)\n",
    "# Get lat min, max\n",
    "aoi_lat = [float(aoi.total_bounds[1]), float(aoi.total_bounds[3])]\n",
    "aoi_lon = [float(aoi.total_bounds[0]), float(aoi.total_bounds[2])]\n",
    "# The netcdf files use a global lat/lon so adjust values accordingly\n",
    "aoi_lon[0] = aoi_lon[0] + 360\n",
    "aoi_lon[1] = aoi_lon[1] + 360\n",
    "\n",
    "aoi_lon, aoi_lat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# specify ESMs, variables, experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The CMIP6 ESM we want to emulate and the variables we want to\n",
    "# emulate\n",
    "\n",
    "\n",
    "esm = ['CAMS-CSM1-0', 'MIROC6', 'GFDL-ESM4', 'FGOALS-g3',\n",
    "'MPI-ESM1-2-HR', 'MPI-ESM1-2-LR', 'MRI-ESM2-0',\n",
    "'ACCESS-ESM1-5', 'IPSL-CM6A-LR', 'CESM2-WACCM',\n",
    "#'UKESM1-0-LL',\n",
    "'CanESM5']\n",
    "vars1 = ['pr']\n",
    "\n",
    "exps = ['historical','ssp119', 'ssp126', 'ssp245', 'ssp370', 'ssp460', 'ssp585',\n",
    "        'ssp434', 'ssp534-over']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pull pangeo dataframe with netcdf addresses for above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pangeo table of ESMs for reference\n",
    "pangeo_path = pkg_resources.resource_filename('stitches', 'data/pangeo_table.csv')\n",
    "pangeo_data = pd.read_csv(pangeo_path)\n",
    "# print(np.sort(pangeo_data.variable.unique()))\n",
    "pangeo_data = pangeo_data[((\n",
    "                               (pangeo_data['variable'].isin(vars1)) )  )\n",
    "                          & ((pangeo_data['domain'].str.contains('mon')) ) &\n",
    "                           ((pangeo_data['experiment'].isin(exps))) &\n",
    "                           (pangeo_data['model'].isin(esm))].copy()\n",
    "\n",
    "print(pangeo_data.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# loop over files and do calculations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pr_holder = pd.DataFrame()\n",
    "\n",
    "for esmname in esm[0:1]:\n",
    "  for exp in exps[0:5]:\n",
    "\n",
    "    print(esmname)\n",
    "    print(exp)\n",
    "    df_ens_avg = 0\n",
    "\n",
    "    filelist = pangeo_data[(pangeo_data['model'] ==esmname) & (pangeo_data['experiment'] == exp)].copy()\n",
    "\n",
    "    # For all ensemble members in this experiment:\n",
    "    if not filelist.empty:\n",
    "      df_sum = 0\n",
    "      n_good_files = 0\n",
    "      # for each ensemble netcdf:\n",
    "      for i in range(len(filelist)):\n",
    "        print(i)\n",
    "\n",
    "        # Load data and mask to aoi:\n",
    "        x = stitches.fx_pangeo.fetch_nc(filelist.iloc[i].zstore)\n",
    "        if (i==0):\n",
    "            aoi_mask = regionmask.mask_3D_geopandas(aoi,\n",
    "                                                    x.lon,\n",
    "                                                    x.lat)\n",
    "        # # for testing if masking is happening right\n",
    "        # x.sel(time=slice(ref_start, '1995-01-31')).pr.to_dataframe().reset_index().to_csv('test2.csv', index=False)\n",
    "        #\n",
    "        # x = x.sel(time=slice(ref_start, '1995-01-31'),\n",
    "        # lon = slice(aoi_lon[0], aoi_lon[1]),\n",
    "        # lat = slice(aoi_lat[0], aoi_lat[1])).where(aoi_mask).copy()\n",
    "        # x1 = x.pr.to_dataframe().dropna().reset_index().drop(['region'], axis=1).reset_index(drop=True).copy()\n",
    "        # x1.to_csv('test.csv', index=False)\n",
    "        x = x.sel(lon = slice(aoi_lon[0], aoi_lon[1]),\n",
    "                  lat = slice(aoi_lat[0], aoi_lat[1])).where(aoi_mask).copy()\n",
    "\n",
    "        # If the experiment is historical, further slice to reference years.\n",
    "        # Otherwise, slice to comparison years:\n",
    "        if (exp == 'historical'):\n",
    "            x = x.sel(time=slice(ref_start, ref_end)).copy()\n",
    "        else:\n",
    "            x = x.sel(time=slice(comp_start, comp_end)).copy()\n",
    "\n",
    "        # Check if there are the correct number of time steps in this\n",
    "        # sliced data:\n",
    "        # Very rough QC for checking complete netcdfs and assumes\n",
    "        # comparison window and reference window same length.\n",
    "        if (len(x.time) >= 12*window_length):\n",
    "            # coerce to DF so we can properly lat weight to do spatial aggregation:\n",
    "            x1 = x.pr.to_dataframe().dropna().reset_index().drop(['region'],\n",
    "                                                                 axis=1).reset_index(drop=True).copy()\n",
    "            # spatial aggregation:\n",
    "            monthly_aoi_pr = pd.DataFrame()\n",
    "            for name, group in x1.groupby('time'):\n",
    "                lat = group['lat']\n",
    "                area = np.cos(np.deg2rad(lat))\n",
    "                df = pd.DataFrame({'time': group['time'].drop_duplicates()})\n",
    "                df['aggregate_pr'] = sum(area * group['pr'])/sum(area)\n",
    "                monthly_aoi_pr = pd.concat([df, monthly_aoi_pr]).reset_index(drop=True).copy()\n",
    "                del(df)\n",
    "                del(area)\n",
    "                del(lat)\n",
    "                # end for loop over months to do spatial disaggregation\n",
    "\n",
    "            # time average for this ensemble member:\n",
    "            aoi_pr = monthly_aoi_pr['aggregate_pr'].mean().copy()\n",
    "\n",
    "            # and add it to the running sum for the ensemble members\n",
    "            df_sum = (aoi_pr  + df_sum).copy()\n",
    "            n_good_files = n_good_files + 1\n",
    "        # end for loop over files in the experiment\n",
    "\n",
    "    # Calculate the ensemble average of CONUS 20 year average precip for this\n",
    "    # experiment\n",
    "    df_ens_avg = df_sum/n_good_files\n",
    "\n",
    "    # and append to the pr holding data frame\n",
    "    pr_holder = pd.concat([pr_holder,\n",
    "                           pd.DataFrame({'esm':esmname,\n",
    "                                         'experiment':exp,\n",
    "                                         'ens_avg_pr':df_ens_avg}\n",
    "                                        )]).reset_index(drop=True).copy()\n",
    "    del(filelist)\n",
    "    del(df_ens_avg)\n",
    "    # end loop over experiments\n",
    "# end loop over esms\n",
    "\n",
    "\n",
    "#%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-58c3bd78",
   "language": "python",
   "display_name": "PyCharm (python_curation)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}